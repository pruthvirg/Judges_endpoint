<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Endpoint Model</title>
  
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    
    <meta name="description" content="">
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/toastify-js/src/toastify.min.css">
    <!-- Bootstrap CSS -->
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/css/bootstrap.min.css"
        integrity="sha384-Gn5384xqQ1aoWXA+058RXPxPg6fy4IWvTNh0E263XmFcJlSAwiGgFAW/dAiS6JXm" crossorigin="anonymous">
    <!-- Optional JavaScript -->
    <!-- jQuery first, then Popper.js, then Bootstrap JS -->
    <script src="https://code.jquery.com/jquery-3.2.1.slim.min.js"
        integrity="sha384-KJ3o2DKtIkvYIK3UENzmM7KCkRr/rE9/Qpg6aAZGJwFDMVNA/GpGFF93hXpG5KkN"
        crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.12.9/umd/popper.min.js"
        integrity="sha384-ApNbgh9B+Y1QKtv3Rn7W3mgPxhU9K/ScQsAP7hUibX39j7fakFPskvXusvfa0b4Q"
        crossorigin="anonymous"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/js/bootstrap.min.js"
        integrity="sha384-JZR6Spejh4U02d8jOt6vLEHfe/JQGiRRSQQxSfFWpi1MquVdAyjUar5+76PVCmYl"
        crossorigin="anonymous"></script>

</head>
<body>
    


<div class="row mx-5">
    <div class="col-6">
        <div class='teachable'>
            <div>Teachable Machine Pose Model</div>
            <button type="button" onclick="init()">Start</button>
            <div><canvas id="canvas"></canvas></div>

            <!-- Pose model results -->
            Full Face Visible
            <div class="progress mb-3">
                <div class="progress-bar bg-success" id="face1" role="progressbar" style="width: 0;" ></div>
            </div>

            Face Partially Hidden
            <div class="progress mb-3">
                <div class="progress-bar bg-danger" id="face2" role="progressbar" style="width: 0;" ></div>
            </div>

            <hr>
            <hr>


            <!-- Face posture results -->
            Face Looking Straight At Screen
            <div class="progress mb-3">
                <div class="progress-bar bg-success" id="face3" role="progressbar" style="width: 0;" ></div>
            </div>

            Face Looking Elsewhere
            <div class="progress mb-3">
                <div class="progress-bar bg-danger" id="face4" role="progressbar" style="width: 0;" ></div>
            </div>

            <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@1.3.1/dist/tf.min.js"></script>
            <script src="https://cdn.jsdelivr.net/npm/@teachablemachine/pose@0.8/dist/teachablemachine-pose.min.js"></script>
            <script src="https://cdn.jsdelivr.net/npm/@teachablemachine/image@0.8/dist/teachablemachine-image.min.js"></script>
            <script type="text/javascript">                
                // More API functions here:
                // https://github.com/googlecreativelab/teachablemachine-community/tree/master/libraries/pose
            
                // the link to your model provided by Teachable Machine export panel
                let model, webcam, ctx, labelContainer, maxPredictions;
                var num = 0;
                var ans = 0;
                var num_2 = 0;
                var ans_2 = 0;
                async function init() {
                    const modelURL = "https://teachablemachine.withgoogle.com/models/-0vzxspVM/" + "model.json";
                    const metadataURL = "https://teachablemachine.withgoogle.com/models/-0vzxspVM/" + "metadata.json";
            
                    const modelURL_2 = "https://teachablemachine.withgoogle.com/models/ja7WndZ1g/" + "model.json";
                    const metadataURL_2 = "https://teachablemachine.withgoogle.com/models/ja7WndZ1g/" + "metadata.json";
                    // load the model and metadata
                    // Refer to tmImage.loadFromFiles() in the API to support files from a file picker
                    // Note: the pose library adds a tmPose object to your window (window.tmPose)
                    model = await tmPose.load(modelURL, metadataURL);
                    maxPredictions = model.getTotalClasses();
            
                    model_2 = await tmImage.load(modelURL_2, metadataURL_2);
                    maxPredictions_2 = model_2.getTotalClasses();
                    console.log('models_loaded');
                    // Convenience function to setup a webcam
                    const size = 200;
                    const flip = true; // whether to flip the webcam
                    webcam = new tmPose.Webcam(size, size, flip); // width, height, flip
                    await webcam.setup(); // request access to the webcam
                    await webcam.play();
                    window.requestAnimationFrame(loop);
            
                    // append/get elements to the DOM
                    const canvas = document.getElementById("canvas");
                    canvas.width = size; canvas.height = size;
                    ctx = canvas.getContext("2d");

                    console.log('canvas setup done');
                }
            
                async function loop(timestamp) {
                    webcam.update(); // update the webcam frame
                    await predict(model, model_2, maxPredictions, maxPredictions_2);
                    window.requestAnimationFrame(loop);
                   
                }

                
            
                async function predict(model = model, model_2 = model_2,maxPredictions = maxPredictions, maxPredictions_2 =maxPredictions_2) {
                    // Prediction #1: run input through posenet
                    // estimatePose can take in an image, video or canvas html element
                    const { pose, posenetOutput } = await model.estimatePose(webcam.canvas);
                    const prediction = await model.predict(posenetOutput);
                    const prediction_2 = await model_2.predict(webcam.canvas);
                    // console.log('done with predicitons for both models');
                    
                    let score1 = prediction[0].probability.toFixed(2) * 100
                    let score2 = prediction[1].probability.toFixed(2) * 100
                    document.getElementById("face1").style.width =  `${score1}%`
                    document.getElementById("face1").innerHTML = `${score1}%`
                    document.getElementById("face2").style.width =  `${score2}%`
                    document.getElementById("face2").innerHTML = `${score2}%`

                    let score3 = prediction_2[0].probability.toFixed(2) * 100
                    let score4 = prediction_2[1].probability.toFixed(2) * 100
                    document.getElementById("face3").style.width =  `${score3}%`
                    document.getElementById("face3").innerHTML = `${score3}%`
                    document.getElementById("face4").style.width =  `${score4}%`
                    document.getElementById("face4").innerHTML = `${score4}%`
   
                    num += 1;
                    num_2 += 1;
                    ans += parseFloat(prediction[1].probability.toFixed(2));
                    ans_2 += parseFloat(prediction_2[1].probability.toFixed(2));
                
                    if(num > 50 && ans/num > 0.7) {

                        Toastify({
                            text: "Ensure that your face is fully visible!",
                            duration: 5000, 
                            close: true,
                            gravity: "top", // `top` or `bottom`
                            position: 'right', // `left`, `center` or `right`
                            backgroundColor: "#FF0725",
                            stopOnFocus: true, // Prevents dismissing of toast on hover
                        }).showToast();

                        // console.log(canvas.toDataURL('image/png'))
                        console.log("Frames sent to S3!")
                        // alert("FACE NOT DETECTED!!!");
                        ans = 0;
                        num = 0;
                        ans_2 = 0;
                        num_2 = 0;
                        
                    } else if (num > 50) {
                        ans = 0;
                        num = 0;
                    }

                    if(num_2 > 55 && ans_2/num_2 > 0.5) {

                        Toastify({
                            text: "Ensure that your face is looking at the screen!",
                            duration: 5000, 
                            close: true,
                            gravity: "top", // `top` or `bottom`
                            position: 'right', // `left`, `center` or `right`
                            backgroundColor: "#CD4242",
                            stopOnFocus: true, // Prevents dismissing of toast on hover
                        }).showToast();

                        console.log("Frames sent to S3!")

                        // alert("PLEASE FOCUS ON THE EXAM SCREEN!!!");

                        ans_2 = 0;
                        num_2 = 0;
                        num = 0;
                        ans = 0;

                    } else if (num_2 > 55) {
                        ans_2 = 0;
                        num_2 = 0;
                    }             

                    // finally draw the poses
                    drawPose(pose);
                }
            
                function drawPose(pose) {
                    if (webcam.canvas) {
                        ctx.drawImage(webcam.canvas, 0, 0);
                        // draw the keypoints and skeleton
                        if (pose) {
                            const minPartConfidence = 0.5;
                            tmPose.drawKeypoints(pose.keypoints, minPartConfidence, ctx);
                            tmPose.drawSkeleton(pose.keypoints, minPartConfidence, ctx);
                        }
                    }
                }
            </script>
        </div>
    </div>

    <div class="col-6">
        <div>Teachable Machine Audio Model</div>
        <button class="mb-3" type="button" onclick="init_audio()">Start</button>

        

        Background Noise
        <div class="progress mb-3">
            <div class="progress-bar bg-success" id="audio1" role="progressbar" style="width: 0;" ></div>
        </div>

        Voice Activity Detected 
        <div class="progress mb-3">
            <div class="progress-bar bg-danger" id="audio2" role="progressbar" style="width: 0;" ></div>
        </div>
    </div>

</div>

<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@1.3.1/dist/tf.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/speech-commands@0.4.0/dist/speech-commands.min.js"></script>

<script type="text/javascript">
    // more documentation available at
    // https://github.com/tensorflow/tfjs-models/tree/master/speech-commands

    // the link to your model provided by Teachable Machine export panel
    const URL = "https://teachablemachine.withgoogle.com/models/PDzS64b9W/";
    var num_3 = 0;
    var ans_3 = 0;

    async function createModel() {
        const checkpointURL = URL + "model.json"; // model topology
        const metadataURL = URL + "metadata.json"; // model metadata

        const recognizer = speechCommands.create(
            "BROWSER_FFT", // fourier transform type, not useful to change
            undefined, // speech commands vocabulary feature, not useful for your models
            checkpointURL,
            metadataURL);

        // check that model and metadata are loaded via HTTPS requests.
        await recognizer.ensureModelLoaded();

        return recognizer;
    }

    async function init_audio() {
        const recognizer = await createModel();
        // const [backgroundNoise, suspectedVoice] = recognizer.wordLabels(); // get class labels
        // console.log(backgroundNoise)
        // console.log(suspectedVoice)

        // const labelContainer_audio = document.getElementById("label-container_audio");
        // for (let i = 0; i < classLabels.length; i++) {
        //     labelContainer_audio.appendChild(document.createElement("div"));
        // }

        // listen() takes two arguments:
        // 1. A callback function that is invoked anytime a word is recognized.
        // 2. A configuration object with adjustable fields
        recognizer.listen(result => {
            const scores = result.scores; // probability of prediction for each class
            // render the probability scores per class

            let score1 = result.scores[0].toFixed(2) * 100
            let score2 = result.scores[1].toFixed(2) * 100


            document.getElementById("audio1").style.width =  `${score1}%`
            document.getElementById("audio1").innerHTML = `${score1}%`

            document.getElementById("audio2").style.width =  `${score2}%`
            document.getElementById("audio2").innerHTML = `${score2}%`



            // for (let i = 1; i <= 2; i++) {
            //     const classPrediction_audio = classLabels[i] + ": " + result.scores[i].toFixed(2);


                // console.log("%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%")
                // console.log("classPrediction_audio: " + classPrediction_audio)
                // console.log("%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%")

                // labelContainer_audio.childNodes[i].innerHTML = classPrediction_audio;

            // }
            
        num_3 += 1;
        ans_3 += parseFloat(result.scores[1].toFixed(2));

       
        if(num_3 > 4 && ans_3/num_3 > 0.7) {
            Toastify({
                        text: "Ensure that there is no one talking!",
                        duration: 5000, 
                        close: true,
                        gravity: "top", // `top` or `bottom`
                        position: 'right', // `left`, `center` or `right`
                        backgroundColor: "#F853FF",
                        stopOnFocus: true, // Prevents dismissing of toast on hover
                    }).showToast();
                 
            // alert("STOP DISCUSSING AND MAINTAIN SILENCE!!!");

            ans_3 = 0;
            num_3 = 0;
        } else if (num_3 > 4) {
            ans_3 = 0;
            num_3 = 0;
        }
        }, {
            includeSpectrogram: true, // in case listen should return result.spectrogram
            probabilityThreshold: 0.75,
            invokeCallbackOnNoiseAndUnknown: true,
            overlapFactor: 0.50 // probably want between 0.5 and 0.75. More info in README
        });

        // Stop the recognition in 5 seconds.
        // setTimeout(() => recognizer.stopListening(), 5000);

    }
</script>
<script type="text/javascript" src="https://cdn.jsdelivr.net/npm/toastify-js"></script>



</div>
</body>
</html>
